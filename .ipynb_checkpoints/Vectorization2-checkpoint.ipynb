{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77d5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Science in TSE Systems/MISP Project\n",
    "#Code written by: Anshak Mallik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa46fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import nltk\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f08d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gillard/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3172: DtypeWarning: Columns (0,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Getting the dataframe from Attributes.csv\n",
    "data_folder = \"/home/gillard/Bureau/MISP_Analysis/Back-up/WEIS2022\"\n",
    "attributes = pd.read_csv(f\"{data_folder}/Attributes.csv\")  #dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b0199",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161690bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      http://fastchem.co.id/muri/config.bin\n",
      "1                         http://fastchem.co.id/muri/bot.exe\n",
      "2                        http://fastchem.co.id/muri/gate.php\n",
      "3                      http://fastchem.co.id/kays/config.bin\n",
      "4                         http://fastchem.co.id/kays/bot.exe\n",
      "                                 ...                        \n",
      "9423337                                      188.120.241.150\n",
      "9423338    http://audio.mesomedia.co.uk/forums/viewtopic....\n",
      "9423339    http://audio.mesomedia.co.uk/factor.xpd?import...\n",
      "9423340    http://audio.mesomedia.co.uk/forums/viewtopic....\n",
      "9423341                                    Driveby:Angler EK\n",
      "Name: Value, Length: 9423342, dtype: object\n"
     ]
    }
   ],
   "source": [
    "value = attributes['Value'].astype(str)\n",
    "\n",
    "attribute_type = attributes['Attribute Type']\n",
    "\n",
    "def normalize(tokens):\n",
    "    '''\n",
    "    INPUT:  - tokens: list of tokens represented as strings\n",
    "    OUTPUT: - normalized_tokens: list of input tokens which have been normalized\n",
    "    '''\n",
    "    \n",
    "    normalized_tokens = []\n",
    "    \n",
    "    for token, i in zip(tokens, range(len(tokens))):\n",
    "        \n",
    "        #Removing punctuation\n",
    "        if attribute_type[i] != ('ip-dst' or 'ip-dst|port' or 'ip-src' or 'ip-src|port'):\n",
    "            \n",
    "            #Removing 'http[s]://' and 'www' from beginning of urls\n",
    "            if (token.startswith('http')):\n",
    "                token = re.sub('http[s]?://','', token)\n",
    "            if (token.startswith('www')):\n",
    "                token = re.sub('www', '', token)\n",
    "                \n",
    "            #Remove punctuation\n",
    "            token = re.sub(r'[^\\w\\s]', '', token)\n",
    "        \n",
    "        #Making all tokens lower case\n",
    "        token = token.lower()\n",
    "        \n",
    "        #Appending to list\n",
    "        normalized_tokens.append(token)\n",
    "    \n",
    "    return normalized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d24c3d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16297/2840603731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Changing values to normalised values in dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnormalised_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalised_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16297/215894498.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#Removing 'http[s]://' and 'www' from beginning of urls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http[s]?://'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'www'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "#Changing values to normalised values in dataframe\n",
    "normalised_values = normalize(value)\n",
    "attributes['Value'] = pd.Series(normalised_values)\n",
    "value = attributes['Value'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ffd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "#Creating list with all event IDs (without repetition)\n",
    "event_ids = attributes['Event ID']\n",
    "events = list(OrderedDict.fromkeys(event_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3e9c8",
   "metadata": {},
   "source": [
    "## Inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop to see which events have number of values of tolerance\n",
    "tol = 5e3\n",
    "counter = 0\n",
    "big_events = []\n",
    "big_indices = []\n",
    "\n",
    "for k in range(len(events)):\n",
    "    #Getting relevant rows and their attribute IDs\n",
    "    event_df = attributes.loc[attributes['Event ID'] == events[k]]\n",
    "    n = len(event_df)\n",
    "    attribute_ids = event_df['Attribute ID']\n",
    "    values = np.array(event_df['Value'])\n",
    "    if len(values) >= tol: \n",
    "        print('The following event has too many values (more than %d)!' % (tol))\n",
    "        print('Index %d, Event ID %d, Values %d' % (k, events[k], len(values)))\n",
    "        print('----------')\n",
    "        counter += 1\n",
    "        big_events.append(events[k])\n",
    "        big_indices.append(k)\n",
    "        \n",
    "print('Total number of events with values over %d: %d' % (tol, counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering events before getting attribute IDs\n",
    "filtered_events = [x for x in events if x not in big_events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from timeit import default_timer as timer\n",
    "# from datetime import timedelta\n",
    "# from difflib import SequenceMatcher\n",
    "# # import jellyfish as jl\n",
    "\n",
    "# #Creating subset matrix for example\n",
    "\n",
    "# #Begin timer before loop\n",
    "# start = timer()\n",
    "\n",
    "# #Getting subset data\n",
    "# N = 100\n",
    "# attribute_ids_N = np.array(attributes['Attribute ID'][:N]) #Series\n",
    "# values_N = value[:N] #After normalization\n",
    "\n",
    "# #Empty matrix\n",
    "# I = np.zeros((N, N))\n",
    "# for i in range(N):\n",
    "#     for j in range(N):\n",
    "#         if (i >= j):\n",
    "#             I[i,j] = round(SequenceMatcher(None, values_N[i], values_N[j]).ratio(), 3)\n",
    "#             # I[i,j] = round(jl.jaro_similarity(values_N[i], values_N[j]), 3)\n",
    "            \n",
    "# #Matrix as dataframe\n",
    "# df = pd.DataFrame(I, index=attribute_ids_N, columns=attribute_ids_N)\n",
    "# # df.to_csv(r'Data/Inheritance_subset.csv')\n",
    "\n",
    "# #End timer after loop    \n",
    "# end = timer()\n",
    "# print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bcc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "#Getting list of all event and attribute IDs separately\n",
    "start = timer()\n",
    "e, a, index = [], [], []\n",
    "for k in range(len(filtered_events)):\n",
    "    \n",
    "    #Filtering using events\n",
    "    df = attributes.loc[attributes['Event ID'] == filtered_events[k]]\n",
    "    #Attribute ID\n",
    "    attribute_ids = df['Attribute ID']\n",
    "    \n",
    "    #Indices of rows\n",
    "    index_list = list(df.index)\n",
    "    index += index_list\n",
    "    #Appending e and a\n",
    "    for l in range(len(attribute_ids)):\n",
    "        e.append(filtered_events[k])\n",
    "        a.append(np.array(attribute_ids)[l])\n",
    "        \n",
    "    #Checkpoints\n",
    "    if k%1000 == 0:\n",
    "        print('%d iterations done in: ' % (k))\n",
    "        print(timedelta(seconds=timer()-start))\n",
    "        print('----------')\n",
    "print(timedelta(seconds=timer()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "#Creating matrix\n",
    "\n",
    "#Getting the data\n",
    "N = len(index)\n",
    "labels = [(ev, at) for ev, at in zip(e, a)]\n",
    "values = value[index]\n",
    "\n",
    "#Begin timer before loop\n",
    "start = timer()\n",
    "\n",
    "#Empty matrix\n",
    "I = np.zeros((N, N))    \n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if (i >= j):\n",
    "            I[i,j] = round(SequenceMatcher(None, values[i], values[j]).ratio(), 3)\n",
    "    #Checkpoints\n",
    "    if i%1000 == 0:\n",
    "        print('%d iterations done in: ' % (k))\n",
    "        print(timedelta(seconds=timer()-start))\n",
    "        print('----------')\n",
    "        \n",
    "#Matrix as dataframe\n",
    "print('-------------------- \\n%Saving to .csv%')\n",
    "df = pd.DataFrame(I, index=labels, columns=labels)\n",
    "df.to_csv(r'Data/Inheritance.csv')\n",
    "\n",
    "#End timer after loop    \n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf85db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
