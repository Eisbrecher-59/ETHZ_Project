{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77d5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Science in TSE Systems/MISP Project\n",
    "#Code written by: Anshak Mallik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa46fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f08d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the dataframe from Attributes.csv\n",
    "data_folder = \"Data\"\n",
    "attributes = pd.read_csv(f\"{data_folder}/Attributes.csv\")  #dataframe\n",
    "# attributes = attributes[attributes[\"Orgc ID\"] != 1203]\n",
    "column_names = attributes.columns #names of columns in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b0199",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161690bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = attributes['Value']\n",
    "attribute_type = attributes['Attribute Type']\n",
    "\n",
    "def normalize(tokens):\n",
    "    '''\n",
    "    INPUT:  - tokens: list of tokens represented as strings\n",
    "    OUTPUT: - normalized_tokens: list of input tokens which have been normalized\n",
    "    '''\n",
    "    \n",
    "    normalized_tokens = []\n",
    "    \n",
    "    for token, i in zip(tokens, range(len(tokens))):\n",
    "        \n",
    "        #Removing punctuation\n",
    "        if attribute_type[i] != ('ip-dst' or 'ip-dst|port' or 'ip-src' or 'ip-src|port'):\n",
    "            \n",
    "            #Removing 'http[s]://' and 'www' from beginning of urls\n",
    "            if (token.startswith('http')):\n",
    "                token = re.sub('http[s]?://','', token)\n",
    "            if (token.startswith('www')):\n",
    "                token = re.sub('www', '', token)\n",
    "                \n",
    "            #Remove punctuation\n",
    "            token = re.sub(r'[^\\w\\s]', '', token)\n",
    "        \n",
    "        #Making all tokens lower case\n",
    "        token = token.lower()\n",
    "        \n",
    "        #Appending to list\n",
    "        normalized_tokens.append(token)\n",
    "    \n",
    "    return normalized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing values to normalised values in dataframe\n",
    "normalised_values = normalize(value)\n",
    "attributes['Value'] = pd.Series(normalised_values)\n",
    "value = attributes['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ffd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "#Creating list with all event IDs (without repetition)\n",
    "event_ids = attributes['Event ID']\n",
    "events = list(OrderedDict.fromkeys(event_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3e9c8",
   "metadata": {},
   "source": [
    "## Inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from difflib import SequenceMatcher\n",
    "\n",
    "# #Working with first event ID\n",
    "\n",
    "# #Getting relevant rows and their attribute IDs\n",
    "# event_df = attributes.loc[attributes['Event ID'] == events[0]]\n",
    "# n = len(event_df)\n",
    "# attribute_ids = event_df['Attribute ID']\n",
    "# values = event_df['Value']\n",
    "\n",
    "# #Creating inheritance matrix\n",
    "# I = np.zeros((n,n))\n",
    "# for i in range(n):\n",
    "#     for j in range(n):\n",
    "#         if (i >= j):\n",
    "#             I[i,j] = SequenceMatcher(None, values[i], values[j]).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "m = 1\n",
    "#Empty list to append with (Event ID, inhertiance matrix)\n",
    "event_inheritances = []\n",
    "\n",
    "#Generalising for all event IDs\n",
    "for k in range(len(events[m:m+1])):\n",
    "    \n",
    "    #Getting relevant rows and their attribute IDs\n",
    "    event_df = attributes.loc[attributes['Event ID'] == events[k]]\n",
    "    n = len(event_df)\n",
    "    attribute_ids = event_df['Attribute ID']\n",
    "    values = event_df['Value']\n",
    "\n",
    "    #Creating inheritance matrix\n",
    "    I = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if (i >= j):\n",
    "                I[i,j] = SequenceMatcher(None, values[i], values[j]).ratio()\n",
    "\n",
    "    #Appending to list\n",
    "    event_inheritances.append((events[k], I))\n",
    "    \n",
    "# print(event_inheritances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
